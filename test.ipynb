{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "class LLTM(torch.nn.Module):\n",
    "    def __init__(self, input_features, state_size):\n",
    "        super(LLTM, self).__init__()\n",
    "        self.input_features = input_features\n",
    "        self.state_size = state_size\n",
    "        # 3 * state_size for input gate, output gate and candidate cell gate.\n",
    "        # input_features + state_size because we will multiply with [input, h].\n",
    "        self.weights = torch.nn.Parameter(\n",
    "            torch.empty(3 * state_size, input_features + state_size))\n",
    "        self.bias = torch.nn.Parameter(torch.empty(3 * state_size))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1.0 / math.sqrt(self.state_size)\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-stdv, +stdv)\n",
    "\n",
    "    def forward(self, input, state):\n",
    "        old_h, old_cell = state\n",
    "        X = torch.cat([old_h, input], dim=1)\n",
    "\n",
    "        # Compute the input, output and candidate cell gates with one MM.\n",
    "        gate_weights = F.linear(X, self.weights, self.bias)\n",
    "        # Split the combined gate weight matrix into its components.\n",
    "        gates = gate_weights.chunk(3, dim=1)\n",
    "\n",
    "        input_gate = torch.sigmoid(gates[0])\n",
    "        output_gate = torch.sigmoid(gates[1])\n",
    "        # Here we use an ELU instead of the usual tanh.\n",
    "        candidate_cell = F.elu(gates[2])\n",
    "\n",
    "        # Compute the new cell state.\n",
    "        new_cell = old_cell + candidate_cell * input_gate\n",
    "        # Compute the new hidden state and output.\n",
    "        new_h = torch.tanh(new_cell) * output_gate\n",
    "\n",
    "        return new_h, new_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "batch_size = 256\n",
    "input_features = 32\n",
    "state_size = 32\n",
    "X = torch.randn(batch_size, input_features)\n",
    "h = torch.randn(batch_size, state_size)\n",
    "C = torch.randn(batch_size, state_size)\n",
    "\n",
    "rnn = LLTM(input_features, state_size)\n",
    "\n",
    "new_h, new_C = rnn(X, (h, C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tb_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mGetoptError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32md:\\Anaconda\\envs\\unidl\\lib\\site-packages\\setuptools\\_distutils\\fancy_getopt.py:246\u001b[0m, in \u001b[0;36mFancyGetopt.getopt\u001b[1;34m(self, args, object)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 246\u001b[0m     opts, args \u001b[39m=\u001b[39m getopt\u001b[39m.\u001b[39;49mgetopt(args, short_opts, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlong_opts)\n\u001b[0;32m    247\u001b[0m \u001b[39mexcept\u001b[39;00m getopt\u001b[39m.\u001b[39merror \u001b[39mas\u001b[39;00m msg:\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\unidl\\lib\\getopt.py:93\u001b[0m, in \u001b[0;36mgetopt\u001b[1;34m(args, shortopts, longopts)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[39mif\u001b[39;00m args[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39m--\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m---> 93\u001b[0m     opts, args \u001b[39m=\u001b[39m do_longs(opts, args[\u001b[39m0\u001b[39;49m][\u001b[39m2\u001b[39;49m:], longopts, args[\u001b[39m1\u001b[39;49m:])\n\u001b[0;32m     94\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\unidl\\lib\\getopt.py:157\u001b[0m, in \u001b[0;36mdo_longs\u001b[1;34m(opts, opt, longopts, args)\u001b[0m\n\u001b[0;32m    155\u001b[0m     opt, optarg \u001b[39m=\u001b[39m opt[:i], opt[i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m:]\n\u001b[1;32m--> 157\u001b[0m has_arg, opt \u001b[39m=\u001b[39m long_has_args(opt, longopts)\n\u001b[0;32m    158\u001b[0m \u001b[39mif\u001b[39;00m has_arg:\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\unidl\\lib\\getopt.py:174\u001b[0m, in \u001b[0;36mlong_has_args\u001b[1;34m(opt, longopts)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m possibilities:\n\u001b[1;32m--> 174\u001b[0m     \u001b[39mraise\u001b[39;00m GetoptError(_(\u001b[39m'\u001b[39m\u001b[39moption --\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m not recognized\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m%\u001b[39m opt, opt)\n\u001b[0;32m    175\u001b[0m \u001b[39m# Is there an exact match?\u001b[39;00m\n",
      "\u001b[1;31mGetoptError\u001b[0m: option --ip not recognized",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mDistutilsArgError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32md:\\Anaconda\\envs\\unidl\\lib\\site-packages\\setuptools\\_distutils\\core.py:172\u001b[0m, in \u001b[0;36msetup\u001b[1;34m(**attrs)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m     ok \u001b[39m=\u001b[39m dist\u001b[39m.\u001b[39;49mparse_command_line()\n\u001b[0;32m    173\u001b[0m \u001b[39mexcept\u001b[39;00m DistutilsArgError \u001b[39mas\u001b[39;00m msg:\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\unidl\\lib\\site-packages\\setuptools\\_distutils\\dist.py:467\u001b[0m, in \u001b[0;36mDistribution.parse_command_line\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    466\u001b[0m parser\u001b[39m.\u001b[39mset_aliases({\u001b[39m'\u001b[39m\u001b[39mlicence\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mlicense\u001b[39m\u001b[39m'\u001b[39m})\n\u001b[1;32m--> 467\u001b[0m args \u001b[39m=\u001b[39m parser\u001b[39m.\u001b[39;49mgetopt(args\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscript_args, \u001b[39mobject\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    468\u001b[0m option_order \u001b[39m=\u001b[39m parser\u001b[39m.\u001b[39mget_option_order()\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\unidl\\lib\\site-packages\\setuptools\\_distutils\\fancy_getopt.py:248\u001b[0m, in \u001b[0;36mFancyGetopt.getopt\u001b[1;34m(self, args, object)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[39mexcept\u001b[39;00m getopt\u001b[39m.\u001b[39merror \u001b[39mas\u001b[39;00m msg:\n\u001b[1;32m--> 248\u001b[0m     \u001b[39mraise\u001b[39;00m DistutilsArgError(msg)\n\u001b[0;32m    250\u001b[0m \u001b[39mfor\u001b[39;00m opt, val \u001b[39min\u001b[39;00m opts:\n",
      "\u001b[1;31mDistutilsArgError\u001b[0m: option --ip not recognized",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[20], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m cpp_extension\n\u001b[1;32m----> 4\u001b[0m setup(name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlltm_cpp\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      5\u001b[0m       ext_modules\u001b[39m=\u001b[39;49m[cpp_extension\u001b[39m.\u001b[39;49mCppExtension(\u001b[39m'\u001b[39;49m\u001b[39mlltm_cpp\u001b[39;49m\u001b[39m'\u001b[39;49m, [\u001b[39m'\u001b[39;49m\u001b[39mlltm.cpp\u001b[39;49m\u001b[39m'\u001b[39;49m])],\n\u001b[0;32m      6\u001b[0m       cmdclass\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mbuild_ext\u001b[39;49m\u001b[39m'\u001b[39;49m: cpp_extension\u001b[39m.\u001b[39;49mBuildExtension})\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\unidl\\lib\\site-packages\\setuptools\\__init__.py:87\u001b[0m, in \u001b[0;36msetup\u001b[1;34m(**attrs)\u001b[0m\n\u001b[0;32m     86\u001b[0m _install_setup_requires(attrs)\n\u001b[1;32m---> 87\u001b[0m \u001b[39mreturn\u001b[39;00m distutils\u001b[39m.\u001b[39mcore\u001b[39m.\u001b[39msetup(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mattrs)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\unidl\\lib\\site-packages\\setuptools\\_distutils\\core.py:174\u001b[0m, in \u001b[0;36msetup\u001b[1;34m(**attrs)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[39mexcept\u001b[39;00m DistutilsArgError \u001b[39mas\u001b[39;00m msg:\n\u001b[1;32m--> 174\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mSystemExit\u001b[39;00m(gen_usage(dist\u001b[39m.\u001b[39mscript_name) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39merror: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m msg)\n\u001b[0;32m    176\u001b[0m \u001b[39mif\u001b[39;00m DEBUG:\n",
      "\u001b[1;31mSystemExit\u001b[0m: usage: ipykernel_launcher.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n   or: ipykernel_launcher.py --help [cmd1 cmd2 ...]\n   or: ipykernel_launcher.py --help-commands\n   or: ipykernel_launcher.py cmd --help\n\nerror: option --ip not recognized",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\unidl\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2092\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2089\u001b[0m \u001b[39mif\u001b[39;00m exception_only:\n\u001b[0;32m   2090\u001b[0m     stb \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mAn exception has occurred, use \u001b[39m\u001b[39m%\u001b[39m\u001b[39mtb to see \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   2091\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mthe full traceback.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m]\n\u001b[1;32m-> 2092\u001b[0m     stb\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mInteractiveTB\u001b[39m.\u001b[39;49mget_exception_only(etype,\n\u001b[0;32m   2093\u001b[0m                                                      value))\n\u001b[0;32m   2094\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2095\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   2096\u001b[0m         \u001b[39m# Exception classes can customise their traceback - we\u001b[39;00m\n\u001b[0;32m   2097\u001b[0m         \u001b[39m# use this in IPython.parallel for exceptions occurring\u001b[39;00m\n\u001b[0;32m   2098\u001b[0m         \u001b[39m# in the engines. This should return a list of strings.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\unidl\\lib\\site-packages\\IPython\\core\\ultratb.py:644\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[1;34m(self, etype, value)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_exception_only\u001b[39m(\u001b[39mself\u001b[39m, etype, value):\n\u001b[0;32m    637\u001b[0m     \u001b[39m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \n\u001b[0;32m    639\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[39m    value : exception value\u001b[39;00m\n\u001b[0;32m    643\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 644\u001b[0m     \u001b[39mreturn\u001b[39;00m ListTB\u001b[39m.\u001b[39;49mstructured_traceback(\u001b[39mself\u001b[39;49m, etype, value)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\unidl\\lib\\site-packages\\IPython\\core\\ultratb.py:511\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[0;32m    508\u001b[0m     chained_exc_ids\u001b[39m.\u001b[39madd(\u001b[39mid\u001b[39m(exception[\u001b[39m1\u001b[39m]))\n\u001b[0;32m    509\u001b[0m     chained_exceptions_tb_offset \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    510\u001b[0m     out_list \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 511\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[0;32m    512\u001b[0m             etype, evalue, (etb, chained_exc_ids),\n\u001b[0;32m    513\u001b[0m             chained_exceptions_tb_offset, context)\n\u001b[0;32m    514\u001b[0m         \u001b[39m+\u001b[39m chained_exception_message\n\u001b[0;32m    515\u001b[0m         \u001b[39m+\u001b[39m out_list)\n\u001b[0;32m    517\u001b[0m \u001b[39mreturn\u001b[39;00m out_list\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\unidl\\lib\\site-packages\\IPython\\core\\ultratb.py:1310\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1308\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1309\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtb \u001b[39m=\u001b[39m tb\n\u001b[1;32m-> 1310\u001b[0m \u001b[39mreturn\u001b[39;00m FormattedTB\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[0;32m   1311\u001b[0m     \u001b[39mself\u001b[39;49m, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\unidl\\lib\\site-packages\\IPython\\core\\ultratb.py:1199\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1196\u001b[0m mode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode\n\u001b[0;32m   1197\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose_modes:\n\u001b[0;32m   1198\u001b[0m     \u001b[39m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[1;32m-> 1199\u001b[0m     \u001b[39mreturn\u001b[39;00m VerboseTB\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[0;32m   1200\u001b[0m         \u001b[39mself\u001b[39;49m, etype, value, tb, tb_offset, number_of_lines_of_context\n\u001b[0;32m   1201\u001b[0m     )\n\u001b[0;32m   1202\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mMinimal\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m   1203\u001b[0m     \u001b[39mreturn\u001b[39;00m ListTB\u001b[39m.\u001b[39mget_exception_only(\u001b[39mself\u001b[39m, etype, value)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\unidl\\lib\\site-packages\\IPython\\core\\ultratb.py:1052\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstructured_traceback\u001b[39m(\n\u001b[0;32m   1044\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1045\u001b[0m     etype: \u001b[39mtype\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1049\u001b[0m     number_of_lines_of_context: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m,\n\u001b[0;32m   1050\u001b[0m ):\n\u001b[0;32m   1051\u001b[0m     \u001b[39m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1052\u001b[0m     formatted_exception \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m   1053\u001b[0m                                                            tb_offset)\n\u001b[0;32m   1055\u001b[0m     colors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mColors  \u001b[39m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m     colorsnormal \u001b[39m=\u001b[39m colors\u001b[39m.\u001b[39mNormal  \u001b[39m# used a lot\u001b[39;00m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\unidl\\lib\\site-packages\\IPython\\core\\ultratb.py:953\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m    950\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(tb_offset, \u001b[39mint\u001b[39m)\n\u001b[0;32m    951\u001b[0m head \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_header(etype, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlong_header)\n\u001b[0;32m    952\u001b[0m records \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 953\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_records(etb, number_of_lines_of_context, tb_offset) \u001b[39mif\u001b[39;00m etb \u001b[39melse\u001b[39;00m []\n\u001b[0;32m    954\u001b[0m )\n\u001b[0;32m    956\u001b[0m frames \u001b[39m=\u001b[39m []\n\u001b[0;32m    957\u001b[0m skipped \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\unidl\\lib\\site-packages\\IPython\\core\\ultratb.py:1021\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[1;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1019\u001b[0m \u001b[39mwhile\u001b[39;00m cf \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1020\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1021\u001b[0m         source_file \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39mgetsourcefile(etb\u001b[39m.\u001b[39;49mtb_frame)\n\u001b[0;32m   1022\u001b[0m         lines, first \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39mgetsourcelines(etb\u001b[39m.\u001b[39mtb_frame)\n\u001b[0;32m   1023\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
     ]
    }
   ],
   "source": [
    "from setuptools import setup, Extension\n",
    "from torch.utils import cpp_extension\n",
    "setup(name='lltm_cpp',\n",
    "      ext_modules=[cpp_extension.CppExtension('lltm_cpp', ['lltm.cpp'])],\n",
    "      cmdclass={'build_ext': cpp_extension.BuildExtension})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<setuptools.extension.Extension('lltm_cpp') at 0x1a1eab86ee0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Extension(\n",
    "   name='lltm_cpp',\n",
    "   sources=['lltm.cpp'],\n",
    "   include_dirs=cpp_extension.include_paths(),\n",
    "   language='c++')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'dist'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m cpp_extension\n\u001b[1;32m----> 2\u001b[0m \u001b[39mprint\u001b[39m(cpp_extension\u001b[39m.\u001b[39;49mBuildExtension())\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\unidl\\lib\\site-packages\\torch\\utils\\cpp_extension.py:467\u001b[0m, in \u001b[0;36mBuildExtension.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 467\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    468\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mno_python_abi_suffix \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mno_python_abi_suffix\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    470\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_ninja \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39muse_ninja\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'dist'"
     ]
    }
   ],
   "source": [
    "from torch.utils import cpp_extension\n",
    "print(cpp_extension.BuildExtension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch import nn\n",
    "from torch.autograd import Function\n",
    "import torch\n",
    "\n",
    "import lltm_cpp\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "class LLTMFunction(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, weights, bias, old_h, old_cell):\n",
    "        outputs = lltm_cpp.forward(input, weights, bias, old_h, old_cell)\n",
    "        new_h, new_cell = outputs[:2]\n",
    "        variables = outputs[1:] + [weights]\n",
    "        ctx.save_for_backward(*variables)\n",
    "\n",
    "        return new_h, new_cell\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_h, grad_cell):\n",
    "        d_old_h, d_input, d_weights, d_bias, d_old_cell = lltm_cpp.backward(\n",
    "            grad_h, grad_cell, *ctx.saved_variables)\n",
    "        return d_input, d_weights, d_bias, d_old_h, d_old_cell\n",
    "\n",
    "\n",
    "class LLTM(nn.Module):\n",
    "    def __init__(self, input_features, state_size):\n",
    "        super(LLTM, self).__init__()\n",
    "        self.input_features = input_features\n",
    "        self.state_size = state_size\n",
    "        self.weights = nn.Parameter(\n",
    "            torch.Tensor(3 * state_size, input_features + state_size))\n",
    "        self.bias = nn.Parameter(torch.Tensor(1, 3 * state_size))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1.0 / math.sqrt(self.state_size)\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-stdv, +stdv)\n",
    "\n",
    "    def forward(self, input, state):\n",
    "        return LLTMFunction.apply(input, self.weights, self.bias, *state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "\n",
    "# Our module!\n",
    "import lltm_cpp\n",
    "\n",
    "class LLTMFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, weights, bias, old_h, old_cell):\n",
    "        outputs = lltm_cpp.forward(input, weights, bias, old_h, old_cell)\n",
    "        new_h, new_cell = outputs[:2]\n",
    "        variables = outputs[1:] + [weights]\n",
    "        ctx.save_for_backward(*variables)\n",
    "\n",
    "        return new_h, new_cell\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_h, grad_cell):\n",
    "        outputs = lltm_cpp.backward(\n",
    "            grad_h.contiguous(), grad_cell.contiguous(), *ctx.saved_tensors)\n",
    "        d_old_h, d_input, d_weights, d_bias, d_old_cell = outputs\n",
    "        return d_input, d_weights, d_bias, d_old_h, d_old_cell\n",
    "\n",
    "\n",
    "class LLTM_CPP(torch.nn.Module):\n",
    "    def __init__(self, input_features, state_size):\n",
    "        super(LLTM_CPP, self).__init__()\n",
    "        self.input_features = input_features\n",
    "        self.state_size = state_size\n",
    "        self.weights = torch.nn.Parameter(\n",
    "            torch.empty(3 * state_size, input_features + state_size))\n",
    "        self.bias = torch.nn.Parameter(torch.empty(3 * state_size))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1.0 / math.sqrt(self.state_size)\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-stdv, +stdv)\n",
    "\n",
    "    def forward(self, input, state):\n",
    "        return LLTMFunction.apply(input, self.weights, self.bias, *state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Forward: 4.342 s | Backward 4.159 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "batch_size = 16\n",
    "input_features = 32\n",
    "state_size = 128\n",
    "X = torch.randn(batch_size, input_features)\n",
    "h = torch.randn(batch_size, state_size)\n",
    "C = torch.randn(batch_size, state_size)\n",
    "\n",
    "rnn = LLTM_CPP(input_features, state_size)\n",
    "\n",
    "forward = 0\n",
    "backward = 0\n",
    "for _ in range(10000):\n",
    "    start = time.time()\n",
    "    new_h, new_C = rnn(X, (h, C))\n",
    "    forward += time.time() - start\n",
    "\n",
    "    start = time.time()\n",
    "    (new_h.sum() + new_C.sum()).backward()\n",
    "    backward += time.time() - start\n",
    "\n",
    "print('Forward: {:.3f} s | Backward {:.3f} s'.format(forward, backward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "class LLTM(torch.nn.Module):\n",
    "    def __init__(self, input_features, state_size):\n",
    "        super(LLTM, self).__init__()\n",
    "        self.input_features = input_features\n",
    "        self.state_size = state_size\n",
    "        # 3 * state_size for input gate, output gate and candidate cell gate.\n",
    "        # input_features + state_size because we will multiply with [input, h].\n",
    "        self.weights = torch.nn.Parameter(\n",
    "            torch.empty(3 * state_size, input_features + state_size))\n",
    "        self.bias = torch.nn.Parameter(torch.empty(3 * state_size))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1.0 / math.sqrt(self.state_size)\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-stdv, +stdv)\n",
    "\n",
    "    def forward(self, input, state):\n",
    "        old_h, old_cell = state\n",
    "        X = torch.cat([old_h, input], dim=1)\n",
    "\n",
    "        # Compute the input, output and candidate cell gates with one MM.\n",
    "        gate_weights = F.linear(X, self.weights, self.bias)\n",
    "        # Split the combined gate weight matrix into its components.\n",
    "        gates = gate_weights.chunk(3, dim=1)\n",
    "\n",
    "        input_gate = torch.sigmoid(gates[0])\n",
    "        output_gate = torch.sigmoid(gates[1])\n",
    "        # Here we use an ELU instead of the usual tanh.\n",
    "        candidate_cell = F.elu(gates[2])\n",
    "\n",
    "        # Compute the new cell state.\n",
    "        new_cell = old_cell + candidate_cell * input_gate\n",
    "        # Compute the new hidden state and output.\n",
    "        new_h = torch.tanh(new_cell) * output_gate\n",
    "\n",
    "        return new_h, new_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cpu\n",
      "Forward: 1.375 s | Backward 2.219 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "batch_size = 16\n",
    "input_features = 32\n",
    "state_size = 128\n",
    "device = torch.device('cpu')\n",
    "print('Device',device)\n",
    "X = torch.randn(batch_size, input_features).to(device)\n",
    "h = torch.randn(batch_size, state_size).to(device)\n",
    "C = torch.randn(batch_size, state_size).to(device)\n",
    "\n",
    "rnn = LLTM(input_features, state_size).to(device)\n",
    "\n",
    "forward = 0\n",
    "backward = 0\n",
    "for _ in range(10000):\n",
    "    start = time.time()\n",
    "    new_h, new_C = rnn(X, (h, C))\n",
    "    forward += time.time() - start\n",
    "\n",
    "    start = time.time()\n",
    "    (new_h.sum() + new_C.sum()).backward()\n",
    "    backward += time.time() - start\n",
    "\n",
    "print('Forward: {:.3f} s | Backward {:.3f} s'.format(forward, backward))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Device cuda\n",
    "Forward: 1.257 s | Backward 2.101 s\n",
    "Device cpu\n",
    "Forward: 1.375 s | Backward 2.219 s\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
